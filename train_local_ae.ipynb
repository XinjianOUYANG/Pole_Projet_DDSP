{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a model with z encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please put your audio files in the folder  *./Pretrained_ Models_for_T2/training_ae*\n",
    "\n",
    "### If the training process is termineated, rerun the sections \"Import dependencies\",\"Set paths\" and \"Train model\" sequentially to continue training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check GPU setting\n",
    "\n",
    "**Tensorflow-gpu 2.4 with Cuda 11.0 and CuDnn 8** in order to run by GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "WARNING:tensorflow:From <ipython-input-1-c709a01bba77>:5: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "GPU False\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "print('GPU',tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing successfully\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import gin\n",
    "\n",
    "import ddsp.training\n",
    "from matplotlib import pyplot as plt\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import utils\n",
    "\n",
    "%matplotlib inline\n",
    "sample_rate = 16000\n",
    "\n",
    "print(\"importing successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DRIVE_DIR = './Pretrained_Models_for_T2/training_ae'  \n",
    "assert os.path.exists(DRIVE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Qd22WxEQI3FV"
   },
   "outputs": [],
   "source": [
    "# create all directories leading up to the given directory that do not exist already. \n",
    "# If the given directory already exists, ignore the error.\n",
    "DATA_DIR = os.path.join(DRIVE_DIR, 'data')\n",
    "!mkdir -p \"$DATA_DIR\"\n",
    "AUDIO_DIR = os.path.join(DATA_DIR, 'audio')\n",
    "AUDIO_FILEPATTERN = AUDIO_DIR + '/*'\n",
    "!mkdir -p \"$AUDIO_DIR\"\n",
    "# folder to save the model\n",
    "SAVE_DIR = os.path.join(DRIVE_DIR, 'ddsp_ae_instrument')\n",
    "!mkdir -p \"$SAVE_DIR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Pretrained_Models_for_T2/training_ae/data/train/train.tfrecord*\n"
     ]
    }
   ],
   "source": [
    "# record the training data\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, 'train')\n",
    "!mkdir -p \"$TRAIN_DIR\"\n",
    "TRAIN_TFRECORD = TRAIN_DIR + '/train.tfrecord'\n",
    "TRAIN_TFRECORD_FILEPATTERN = TRAIN_DIR + '/train.tfrecord*'\n",
    "print(TRAIN_TFRECORD_FILEPATTERN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fb4YD8woYD1H"
   },
   "source": [
    "## Prepare Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "itVKEzF6m3rY"
   },
   "outputs": [],
   "source": [
    "mp3_files = glob.glob(os.path.join(DRIVE_DIR, '*.mp3'))\n",
    "wav_files = glob.glob(os.path.join(DRIVE_DIR, '*.wav'))\n",
    "audio_files = mp3_files + wav_files\n",
    "\n",
    "for fname in audio_files:\n",
    "  target_name = os.path.join(AUDIO_DIR, \n",
    "                             os.path.basename(fname).replace(' ', '_'))\n",
    "  print('Copying {} to {}'.format(fname, target_name))\n",
    "  !cp \"$fname\" \"$target_name\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to do some preprocessing on the raw audio you uploaded to get it into the correct format for training. This involves turning the full audio into short (4-second) examples, inferring the fundamental frequency (or \"pitch\") with [CREPE](http://github.com/marl/crepe), and computing the loudness. **These features will then be stored in a sharded [TFRecord](https://www.tensorflow.org/tutorials/load_data/tfrecord) file for easier loading. Depending on the amount of input audio, this process usually takes a few minutes**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ddsp_prepare_tfrecord \\\n",
    "--input_audio_filepatterns=\"$AUDIO_FILEPATTERN \"\\\n",
    "--output_tfrecord_path=\"$TRAIN_TFRECORD\" \\\n",
    "--num_shards=10 \\\n",
    "--alsologtostderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bp_c8P0xApY6"
   },
   "outputs": [],
   "source": [
    "data_provider = ddsp.training.data.TFRecordProvider(TRAIN_TFRECORD_FILEPATTERN)\n",
    "dataset = data_provider.get_dataset(shuffle=False)\n",
    "PICKLE_FILE_PATH = os.path.join(SAVE_DIR, 'dataset_statistics.pkl')\n",
    "\n",
    "utils.save_dataset_statistics(data_provider, PICKLE_FILE_PATH, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nIsq0HrzbOF7"
   },
   "source": [
    "Let's load the dataset in the `ddsp` library and have a look at one of the examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dA-FOmRgYdpZ"
   },
   "outputs": [],
   "source": [
    "data_provider = ddsp.training.data.TFRecordProvider(TRAIN_TFRECORD_FILEPATTERN)\n",
    "dataset = data_provider.get_dataset(shuffle=False)\n",
    "\n",
    "try:\n",
    "  ex = next(iter(dataset))\n",
    "except StopIteration:\n",
    "  raise ValueError(\n",
    "      'TFRecord contains no examples. Please try re-running the pipeline with '\n",
    "      'different audio file(s).')\n",
    "\n",
    "utils.specplot(ex['audio'])\n",
    "\n",
    "f, ax = plt.subplots(3, 1, figsize=(14, 4))\n",
    "x = np.linspace(0, 4.0, 1000)\n",
    "ax[0].set_ylabel('loudness_db')\n",
    "ax[0].plot(x, ex['loudness_db'])\n",
    "ax[1].set_ylabel('F0_Hz')\n",
    "ax[1].set_xlabel('seconds')\n",
    "ax[1].plot(x, ex['f0_hz'])\n",
    "ax[2].set_ylabel('F0_confidence')\n",
    "ax[2].set_xlabel('seconds')\n",
    "ax[2].plot(x, ex['f0_confidence'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(ex['audio'], rate = sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9gvXBa7PbuyY"
   },
   "source": [
    "## Train Model\n",
    "\n",
    "We will now train a \"ae instrument\" model. This means the model is conditioned on the fundamental frequency (f0) and loudness with latent timbre feature z. If you uploaded audio of multiple instruemnts, the neural network you train will attempt to model all timbres, but will likely associate certain timbres with different f0 and loudness conditions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u2lx7yJneUXT"
   },
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "import tensorboard as tb\n",
    "tb.notebook.start('--logdir \"{}\"'.format(SAVE_DIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fT-8Koyvj46w"
   },
   "source": [
    "### We will now begin training. \n",
    "\n",
    "Note that we specify [gin configuration](https://github.com/google/gin-config) files for the both the model architecture ([solo_instrument.gin](TODO)) and the dataset ([tfrecord.gin](TODO)), which are both predefined in the library. You could also create your own. We then override some of the spefic params for `batch_size` (which is defined in in the model gin file) and the tfrecord path (which is defined in the dataset file). \n",
    "\n",
    "### Training Notes:\n",
    "\n",
    "* Models typically perform well when the loss drops to the range of ~4.5-5.0.\n",
    "* Depending on the dataset this can take anywhere from 5k-30k training steps usually.\n",
    "* The default is set to 30k, but you can stop training at any time, and for timbre transfer, it's best to stop before the loss drops too far below ~5.0 to avoid overfitting.\n",
    "* By default, checkpoints will be saved every 300 steps with a maximum of 10 checkpoints (at ~60MB/checkpoint this is ~600MB). Feel free to adjust these numbers depending on the frequency of saves you would like and space on your drive.\n",
    "* If you're restarting a session and `DRIVE_DIR` points a directory that was previously used for training, training should resume at the last checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(TRAIN_TFRECORD_FILEPATTERN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### if you change the path at the begining of this notebook, your must replace the path *'./Pretrained_ Models_for_T2/training_ae/data/train/train.tfrecord*'* in the next cell by the previous print "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "poKO-mZEGYXZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-02 21:25:11.224814: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "I0402 21:25:20.941661 140430025553728 ddsp_run.py:176] Restore Dir: ./Pretrained_Models_for_T2/training_ae/ddsp_ae_instrument\n",
      "I0402 21:25:20.942262 140430025553728 ddsp_run.py:177] Save Dir: ./Pretrained_Models_for_T2/training_ae/ddsp_ae_instrument\n",
      "I0402 21:25:20.943127 140430025553728 resource_reader.py:50] system_path_file_exists:optimization/base.gin\n",
      "E0402 21:25:20.943652 140430025553728 resource_reader.py:55] Path not found: optimization/base.gin\n",
      "I0402 21:25:20.949153 140430025553728 resource_reader.py:50] system_path_file_exists:eval/basic.gin\n",
      "E0402 21:25:20.949429 140430025553728 resource_reader.py:55] Path not found: eval/basic.gin\n",
      "I0402 21:25:20.953716 140430025553728 ddsp_run.py:147] Using operative config: ./Pretrained_Models_for_T2/training_ae/ddsp_ae_instrument/operative_config-0.gin\n",
      "I0402 21:25:20.981163 140430025553728 resource_reader.py:50] system_path_file_exists:models/ae.gin\n",
      "E0402 21:25:20.981485 140430025553728 resource_reader.py:55] Path not found: models/ae.gin\n",
      "I0402 21:25:20.989559 140430025553728 resource_reader.py:50] system_path_file_exists:datasets/tfrecord.gin\n",
      "E0402 21:25:20.990043 140430025553728 resource_reader.py:55] Path not found: datasets/tfrecord.gin\n",
      "I0402 21:25:20.991680 140430025553728 resource_reader.py:50] system_path_file_exists:datasets/base.gin\n",
      "E0402 21:25:20.992074 140430025553728 resource_reader.py:55] Path not found: datasets/base.gin\n",
      "I0402 21:25:21.034230 140430025553728 train_util.py:78] Defaulting to MirroredStrategy\n",
      "2021-04-02 21:25:21.034613: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-04-02 21:25:21.035471: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-04-02 21:25:21.072625: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:b3:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.65GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2021-04-02 21:25:21.072685: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-04-02 21:25:21.072841: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2021-04-02 21:25:21.072948: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2021-04-02 21:25:21.075392: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-04-02 21:25:21.076803: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-04-02 21:25:21.080153: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-04-02 21:25:21.080352: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2021-04-02 21:25:21.081530: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-04-02 21:25:21.081586: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-04-02 21:25:21.082177: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-04-02 21:25:21.082491: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-04-02 21:25:21.082514: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-04-02 21:25:21.082520: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      \n",
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "W0402 21:25:21.083525 140430025553728 cross_device_ops.py:1321] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "I0402 21:25:21.083703 140430025553728 mirrored_strategy.py:350] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "2021-04-02 21:25:21.319708: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-04-02 21:25:21.320045: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3999980000 Hz\n",
      "I0402 21:25:21.509740 140430025553728 trainers.py:137] Building the model...\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "f0_loudness_preprocessor (F0 multiple                  0         \n",
      "_________________________________________________________________\n",
      "mfcc_time_distributed_rnn_en multiple                  843852    \n",
      "_________________________________________________________________\n",
      "rnn_fc_decoder (RnnFcDecoder multiple                  6407334   \n",
      "_________________________________________________________________\n",
      "processor_group (ProcessorGr multiple                  0         \n",
      "_________________________________________________________________\n",
      "spectral_loss (SpectralLoss) multiple                  0         \n",
      "=================================================================\n",
      "Total params: 7,251,186\n",
      "Trainable params: 7,251,186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "I0402 21:25:34.533705 140430025553728 trainers.py:87] Restoring from checkpoint...\n",
      "I0402 21:25:34.533818 140430025553728 trainers.py:95] Trainer restoring the full model\n",
      "I0402 21:25:35.064299 140430025553728 trainers.py:117] Loaded checkpoint ./Pretrained_Models_for_T2/training_ae/ddsp_ae_instrument/ckpt-4000\n",
      "I0402 21:25:35.064504 140430025553728 trainers.py:118] Loading model took 0.5 seconds\n"
     ]
    }
   ],
   "source": [
    "!ddsp_run \\\n",
    "  --mode=train \\\n",
    "  --alsologtostderr \\\n",
    "  --save_dir=\"$SAVE_DIR\" \\\n",
    "  --gin_file=models/ae.gin \\\n",
    "  --gin_file=datasets/tfrecord.gin \\\n",
    "  --gin_param=\"TFRecordProvider.file_pattern='./Pretrained_Models_for_T2/training_ae/data/train/train.tfrecord*'\"\\\n",
    "  --gin_param=\"batch_size=16\" \\\n",
    "  --gin_param=\"train_util.train.num_steps=30000\" \\\n",
    "  --gin_param=\"train_util.train.steps_per_save=200\" \\\n",
    "  --gin_param=\"trainers.Trainer.checkpoints_to_keep=10\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V95qxVjFzWR6"
   },
   "source": [
    "## Resynthesis\n",
    "\n",
    "Check how well the model reconstructs the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OQ5PPDZVzgFR"
   },
   "outputs": [],
   "source": [
    "data_provider = ddsp.training.data.TFRecordProvider(TRAIN_TFRECORD_FILEPATTERN)\n",
    "dataset = data_provider.get_batch(batch_size=1, shuffle=False)\n",
    "\n",
    "try:\n",
    "  batch = next(iter(dataset))\n",
    "except OutOfRangeError:\n",
    "  raise ValueError(\n",
    "      'TFRecord contains no examples. Please try re-running the pipeline with '\n",
    "      'different audio file(s).')\n",
    "\n",
    "# Parse the gin config.\n",
    "gin_file = os.path.join(SAVE_DIR, 'operative_config-0.gin')\n",
    "gin.parse_config_file(gin_file)\n",
    "\n",
    "# Load model\n",
    "model = ddsp.training.models.Autoencoder()\n",
    "model.restore(SAVE_DIR)\n",
    "\n",
    "# Resynthesize audio.\n",
    "outputs = model(batch, training=False)\n",
    "audio_gen = model.get_audio_from_outputs(outputs)\n",
    "audio = batch['audio']\n",
    "\n",
    "print('Original Audio')\n",
    "utils.specplot(audio)\n",
    "\n",
    "print('Resynthesis')\n",
    "utils.specplot(audio_gen)\n",
    "\n",
    "print('\\n','Z value:',outputs['z'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Original Audio')\n",
    "ipd.Audio(audio[0], rate = sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Resynthesis')\n",
    "ipd.Audio(audio_gen[0], rate = sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZXM2ynLQ2Wl3"
   },
   "source": [
    "## SAVE Checkpoint\n",
    "\n",
    "Below you can download the final checkpoint. You are now ready to use it in the [DDSP Timbre Tranfer Colab](https://colab.research.google.com/github/magenta/ddsp/blob/master/ddsp/colab/demos/timbre_transfer.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2WDiCyXP0tNE"
   },
   "outputs": [],
   "source": [
    "CHECKPOINT_ZIP = 'my_ae_instrument.zip'\n",
    "# save the latest checkpoint file\n",
    "latest_checkpoint_fname = os.path.basename(tf.train.latest_checkpoint(SAVE_DIR))\n",
    "!cd \"$SAVE_DIR\" && zip $CHECKPOINT_ZIP $latest_checkpoint_fname* operative_config-0.gin dataset_statistics.pkl\n",
    "!cp \"$SAVE_DIR/$CHECKPOINT_ZIP\" ./ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "hMqWDc_m6rUC"
   ],
   "name": "train_autoencoder.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "ddsp",
   "language": "python",
   "name": "ddsp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
