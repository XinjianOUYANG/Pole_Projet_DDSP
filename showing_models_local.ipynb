{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JXctfLGdacKx"
   },
   "source": [
    "## [Our DDSP project in github](https://github.com/XinjianOUYANG/Pole_Projet_DDSP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Showing the DDSP models we have trained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TUUGDMY5qSdz"
   },
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m2Ol13FaZKwh"
   },
   "outputs": [],
   "source": [
    "# %tensorflow_version 2.x\n",
    "# !pip install -qU ddsp[data_preparation]==1.0.1\n",
    "\n",
    "# Ignore a bunch of deprecation warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import tensorflow.compat.v2 as tf\n",
    "import tensorflow_datasets as tfds \n",
    "import ddsp\n",
    "import utils\n",
    "import os\n",
    "import gin\n",
    "import pickle\n",
    "import matplotlib\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import soundfile as sf \n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import librosa\n",
    "import librosa.display\n",
    " \n",
    "\n",
    "%matplotlib inline\n",
    "sample_rate = 16000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the path of audio and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio path\n",
    "audio_path = 'Pretrained_Models_for_T2/violin_1_model_ae/violin_1.wav'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**the model trained with z encoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model folder direction \n",
    "model_dir_z = 'Pretrained_Models_for_T2/violin_1_model_ae/my_solo_instrument'\n",
    "\n",
    "# dataset_statistics.pkl in .model folder\n",
    "dataset_stats_file_z = os.path.join(model_dir_z, 'dataset_statistics.pkl')\n",
    "\n",
    "# operative_config-0.gin in model folder\n",
    "gin_file_z = os.path.join(model_dir_z, 'operative_config-0.gin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the model trained without z encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hE0_4cJQ0lX1"
   },
   "outputs": [],
   "source": [
    "# model folder direction \n",
    "model_dir = 'Pretrained_ Models_for_T2/DDSP_saxophone_without_z/my_solo_instrument'\n",
    "\n",
    "# dataset_statistics.pkl in .model folder\n",
    "dataset_stats_file = os.path.join(model_dir, 'dataset_statistics.pkl')\n",
    "\n",
    "# operative_config-0.gin in model folder\n",
    "gin_file = os.path.join(model_dir, 'operative_config-0.gin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gzUgnAjhrP9g"
   },
   "source": [
    "## Reading audios and computing (f0,loudness,MFCC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lObag5Jd9amV"
   },
   "source": [
    "### Using the given python file [spectral_ops.py](https://github.com/magenta/ddsp/blob/master/ddsp/spectral_ops.py) in ddsp library to compute $f0$ and loudness.\n",
    "* *ddsp.spectral_ops.compute_f0*\n",
    "\n",
    "* *ddsp.spectral_ops.compute_loudness*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "executionInfo": {
     "elapsed": 570616,
     "status": "ok",
     "timestamp": 1615370354792,
     "user": {
      "displayName": "Xinjian OUYANG",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgDmgUNu_vljWNL53AJFQvh-vkweabOtVRZoY3kWA=s64",
      "userId": "04586718377978961617"
     },
     "user_tz": -60
    },
    "id": "jE5MqZnlMNNa",
    "outputId": "fc206f4f-689b-4efc-a04b-79d8f7d1b7d5"
   },
   "outputs": [],
   "source": [
    "print(audio_path)\n",
    "x_all, sr = sf.read(audio_path) #data,samplerate\n",
    "print('shape of original signal:',np.shape(x_all),'\\n','original sample rate:',sr)\n",
    "sig = x_all[:] # choose the first channel of the original audio\n",
    " \n",
    "# resample (down sampling to 16kHz) and take the first 10 seconds\n",
    "sig_re = librosa.resample(sig,sr,sample_rate)\n",
    "audio = sig_re[:10*sample_rate]\n",
    "print('audio shape:',np.shape(audio))\n",
    "audio = audio[np.newaxis,:]\n",
    "\n",
    "# plot wave form\n",
    "T_all = audio.shape[1]\n",
    "time = np.arange(T_all)/sample_rate\n",
    "plt.figure(figsize=(9,3))\n",
    "plt.plot(time, audio[0])\n",
    "plt.xlabel('time (s)')\n",
    "plt.ylabel('amplitude')\n",
    "\n",
    "# Calculate Spectrogram and plot\n",
    "utils.specplot(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# play audio\n",
    "ipd.Audio(audio[0], rate = sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 778
    },
    "executionInfo": {
     "elapsed": 17211,
     "status": "ok",
     "timestamp": 1615371220642,
     "user": {
      "displayName": "Xinjian OUYANG",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgDmgUNu_vljWNL53AJFQvh-vkweabOtVRZoY3kWA=s64",
      "userId": "04586718377978961617"
     },
     "user_tz": -60
    },
    "id": "0gOzm3pp7vQb",
    "outputId": "928aa139-c5d3-4f66-843f-672db3051b51"
   },
   "outputs": [],
   "source": [
    "#extracting f0 with CREPE\n",
    "ddsp.spectral_ops.reset_crepe()\n",
    "f0_crepe, f0_confidence = ddsp.spectral_ops.compute_f0(audio[0], \n",
    "                                                       sample_rate= sample_rate,\n",
    "                                                       frame_rate=31.25,\n",
    "                                                       viterbi=False)\n",
    "#extracting loudness \n",
    "loudness =ddsp.spectral_ops.compute_loudness(audio[0],\n",
    "                     sample_rate= sample_rate,\n",
    "                     frame_rate=250,\n",
    "                     n_fft=2048,\n",
    "                     ref_db=20.7,\n",
    "                     use_tf=False)\n",
    "\n",
    "# audio_features dictionary\n",
    "audio_features_key = ['audio','f0_hz','f0_confidence','loundness_db']\n",
    "audio_features = dict([(k,[]) for k in audio_features_key])\n",
    "audio_features['audio'] = audio\n",
    "audio_features['f0_hz'] = f0_crepe\n",
    "audio_features['f0_confidence'] = f0_confidence\n",
    "audio_features['loudness_db'] = loudness\n",
    "\n",
    "\n",
    "# Plot Pitch/f0.\n",
    "plt.figure(figsize=(6, 4))\n",
    "f0_crepe_midi = ddsp.core.hz_to_midi(f0_crepe)\n",
    "plt.plot(np.ravel(f0_crepe), label='crepe')\n",
    "plt.ylabel('Pitch (MIDI)')\n",
    "# Plot f0_confidence.\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(np.ravel(f0_confidence), label='f0 confidence')\n",
    "plt.ylabel('f0 confidence')\n",
    "# Plot Loundness.\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(np.ravel(loudness), label='loudness')\n",
    "plt.ylabel('Loudness')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YnXqvk-CVxGL"
   },
   "source": [
    "### Compute z/MFCC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SJugSlvbVVUx"
   },
   "source": [
    "* [DDSP_run](https://github.com/magenta/ddsp/blob/master/ddsp/training/ddsp_run.py)\n",
    "* training withou z encoder [solo_instrument.gin](https://github.com/magenta/ddsp/blob/master/ddsp/training/gin/models/solo_instrument.gin)\n",
    "* training with z encoder [ae.gin](https://github.com/magenta/ddsp/blob/master/ddsp/training/gin/models/ae.gin)\n",
    "\n",
    "**z-encoder**: \n",
    "\n",
    "    The encoder ﬁrst calculates MFCC’s (Mel Frequency Cepstrum Coefﬁcients) from the audio. MFCC is computed from the log-mel-spectrogram of the audio with a FFT size of 1024, 128 bins of frequency range between 20Hz to 8000Hz, overlap of 75%. We use only the ﬁrst 30 MFCCs that correspond to a smoothed spectral envelope. The MFCCs are then passed through a normalization layer (which has learnable shift and scale parameters) and a 512-unit GRU. The GRU outputs (over time) fed to a 512-unit linear layer to obtain z(t). The z embedding reported in this model has 16 dimensions across 250 time-steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dl6b1J5ZC2CN"
   },
   "source": [
    "\n",
    "<img src=\" pictures/Diagram_of_the_z-encoder.jpg \" alt=\"Diagram of the z-encoder\" width=\"800\">\n",
    "\n",
    "* [z encoder](https://github.com/magenta/ddsp/blob/master/ddsp/training/encoders.py) and [MFCC computing file](https://github.com/magenta/ddsp/blob/master/ddsp/spectral_ops.py) in DDSP library\n",
    "* *ddsp.spectral_ops.compute_mfcc*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 500
    },
    "executionInfo": {
     "elapsed": 1171,
     "status": "ok",
     "timestamp": 1615371245992,
     "user": {
      "displayName": "Xinjian OUYANG",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgDmgUNu_vljWNL53AJFQvh-vkweabOtVRZoY3kWA=s64",
      "userId": "04586718377978961617"
     },
     "user_tz": -60
    },
    "id": "FE-TKlVSC8B5",
    "outputId": "57afbd24-7540-4686-932d-9a7e0fb50a8e"
   },
   "outputs": [],
   "source": [
    "#Calculate MFCC(Mel-frequency Cepstral Coefficients)\n",
    "mfccs = ddsp.spectral_ops.compute_mfcc(\n",
    "    audio[0],\n",
    "    lo_hz=20.0,\n",
    "    hi_hz=8000.0,\n",
    "    fft_size=1024,\n",
    "    mel_bins=128,\n",
    "    mfcc_bins=30)\n",
    "\n",
    "# Plot MFCC.\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(np.ravel(mfccs), label='MFCC')\n",
    "plt.ylabel('MFCC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PQThLZ17mW7V"
   },
   "source": [
    "### Another way to compute f0 and loudness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dimxak_jk1e2"
   },
   "outputs": [],
   "source": [
    "# # Setup the session.\n",
    "# ddsp.spectral_ops.reset_crepe()\n",
    "\n",
    "# # Compute features.\n",
    "# audio_features = ddsp.training.metrics.compute_audio_features(audio)\n",
    "# audio_features['loudness_db'] = audio_features['loudness_db'].astype(np.float32)\n",
    "# audio_features_mod = None\n",
    "\n",
    "# TRIM = -15\n",
    "# # Plot Features.\n",
    "# fig, ax = plt.subplots(nrows=3, \n",
    "#                        ncols=1, \n",
    "#                        sharex=True,\n",
    "#                        figsize=(6, 8))\n",
    "# ax[0].plot(audio_features['loudness_db'][:TRIM])\n",
    "# ax[0].set_ylabel('loudness_db')\n",
    "\n",
    "# ax[1].plot(librosa.hz_to_midi(audio_features['f0_hz'][:TRIM]))\n",
    "# ax[1].set_ylabel('f0 [midi]')\n",
    "\n",
    "# ax[2].plot(audio_features['f0_confidence'][:TRIM])\n",
    "# ax[2].set_ylabel('f0 confidence')\n",
    "# _ = ax[2].set_xlabel('Time step [frame]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yQ_iCEY5s9Mc"
   },
   "source": [
    "## Load the model(without z encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AhJuY90m0lX1"
   },
   "source": [
    "### set paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_dir,'\\n',dataset_stats_file,'\\n',gin_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M4K4tMff0lX2"
   },
   "source": [
    "### load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 971476,
     "status": "aborted",
     "timestamp": 1615370755682,
     "user": {
      "displayName": "Xinjian OUYANG",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgDmgUNu_vljWNL53AJFQvh-vkweabOtVRZoY3kWA=s64",
      "userId": "04586718377978961617"
     },
     "user_tz": -60
    },
    "id": "ra1EW2eMAcT5",
    "outputId": "e608c269-3e6d-4146-d5b6-214c88077fa5"
   },
   "outputs": [],
   "source": [
    "# Load the dataset statistics.\n",
    "print(f'Loading dataset statistics from {dataset_stats_file}')\n",
    "try:\n",
    "  if tf.io.gfile.exists(dataset_stats_file):\n",
    "    with tf.io.gfile.GFile(dataset_stats_file, 'rb') as f:\n",
    "      DATASET_STATS = pickle.load(f)\n",
    "except Exception as err:\n",
    "  print('Loading dataset statistics from pickle failed: {}.'.format(err))\n",
    "\n",
    "\n",
    "# Parse gin config,\n",
    "with gin.unlock_config():\n",
    "  gin.parse_config_file(gin_file, skip_unknown=True)\n",
    "\n",
    "# Assumes only one checkpoint in the folder, 'ckpt-[iter]`.\n",
    "ckpt_files = [f for f in tf.io.gfile.listdir(model_dir) if 'ckpt' in f]\n",
    "ckpt_name = ckpt_files[0].split('.')[0]\n",
    "ckpt = os.path.join(model_dir, ckpt_name)\n",
    "\n",
    "# Ensure dimensions and sampling rates are equal\n",
    "time_steps_train = gin.query_parameter('F0LoudnessPreprocessor.time_steps')\n",
    "n_samples_train = gin.query_parameter('Harmonic.n_samples')\n",
    "hop_size = int(n_samples_train / time_steps_train)\n",
    "\n",
    "time_steps = int(audio.shape[1] / hop_size)\n",
    "n_samples = time_steps * hop_size\n",
    "\n",
    "# print(\"===Trained model===\")\n",
    "# print(\"Time Steps\", time_steps_train)\n",
    "# print(\"Samples\", n_samples_train)\n",
    "# print(\"Hop Size\", hop_size)\n",
    "# print(\"\\n===Resynthesis===\")\n",
    "# print(\"Time Steps\", time_steps)\n",
    "# print(\"Samples\", n_samples)\n",
    "# print('')\n",
    "\n",
    "gin_params = [\n",
    "    'Harmonic.n_samples = {}'.format(n_samples),\n",
    "    'FilteredNoise.n_samples = {}'.format(n_samples),\n",
    "    'F0LoudnessPreprocessor.time_steps = {}'.format(time_steps),\n",
    "    'oscillator_bank.use_angular_cumsum = True',  # Avoids cumsum accumulation errors.\n",
    "]\n",
    "\n",
    "with gin.unlock_config():\n",
    "  gin.parse_config(gin_params)\n",
    "\n",
    "\n",
    "# Trim all input vectors to correct lengths \n",
    "for key in ['f0_hz', 'f0_confidence', 'loudness_db']:\n",
    "  audio_features[key] = audio_features[key][:time_steps]\n",
    "audio_features['audio'] = audio_features['audio'][:n_samples]\n",
    "\n",
    "# Set up the model just to predict audio given new conditioning\n",
    "model = ddsp.training.models.Autoencoder()\n",
    "model.restore(ckpt)\n",
    "\n",
    "# Resynthesize audio.\n",
    "outputs = model(audio_features, training=False) # Run the forward pass, add losses, and create a dictionary of outputs.\n",
    "# print(outputs.keys())\n",
    "# dict_keys(['inputs', 'audio', 'f0_hz', 'f0_confidence', 'loundness_db', \n",
    "#           'f0_condience', 'loudness_db', 'f0_scaled', 'ld_scaled', 'amps', \n",
    "#           'harmonic_distribution', 'noise_magnitudes', 'harmonic', 'filtered_noise', \n",
    "#           'add', 'reverb', 'out', 'audio_synth'])\n",
    "\n",
    "'''\n",
    "Another option:\n",
    "outputs = utils.model_loading(audio,audio_features,model_dir,training=False)\n",
    "'''\n",
    "audio_gen = outputs['audio_synth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"original audio\")\n",
    "ipd.Audio(audio, rate = sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Resynthesed audio without z encoder\")\n",
    "ipd.Audio(audio_gen, rate = sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.specplot(audio)\n",
    "plt.title(\"Original\")\n",
    "\n",
    "utils.specplot(audio_gen)\n",
    "_ = plt.title(\"Resynthesis without z encoder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the model(with z)\n",
    "\n",
    "* [autoencoder.py](https://github.com/magenta/ddsp/blob/master/ddsp/training/models/autoencoder.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_dir_z,'\\n',dataset_stats_file_z,'\\n',gin_file_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load the dataset statistics.\n",
    "print(f'Loading dataset statistics from {dataset_stats_file_z}')\n",
    "try:\n",
    "  if tf.io.gfile.exists(dataset_stats_file_z):\n",
    "    with tf.io.gfile.GFile(dataset_stats_file_z, 'rb') as f:\n",
    "      DATASET_STATS_Z = pickle.load(f)\n",
    "except Exception as err:\n",
    "  print('Loading dataset statistics from pickle failed: {}.'.format(err))\n",
    "\n",
    "\n",
    "# Parse gin config,\n",
    "with gin.unlock_config():\n",
    "  gin.parse_config_file(gin_file_z, skip_unknown=True)\n",
    "\n",
    "# Assumes only one checkpoint in the folder, 'ckpt-[iter]`.\n",
    "ckpt_files = [f for f in tf.io.gfile.listdir(model_dir_z) if 'ckpt' in f]\n",
    "ckpt_name = ckpt_files[0].split('.')[0]\n",
    "ckpt = os.path.join(model_dir_z, ckpt_name)\n",
    "\n",
    "# Ensure dimensions and sampling rates are equal\n",
    "time_steps_train = gin.query_parameter('F0LoudnessPreprocessor.time_steps')\n",
    "n_samples_train = gin.query_parameter('Harmonic.n_samples')\n",
    "hop_size = int(n_samples_train / time_steps_train)\n",
    "\n",
    "time_steps = int(audio.shape[1] / hop_size)\n",
    "n_samples = time_steps * hop_size\n",
    "\n",
    "# print(\"===Trained model===\")\n",
    "# print(\"Time Steps\", time_steps_train)\n",
    "# print(\"Samples\", n_samples_train)\n",
    "# print(\"Hop Size\", hop_size)\n",
    "# print(\"\\n===Resynthesis===\")\n",
    "# print(\"Time Steps\", time_steps)\n",
    "# print(\"Samples\", n_samples)\n",
    "# print('')\n",
    "\n",
    "gin_params = [\n",
    "    'Harmonic.n_samples = {}'.format(n_samples),\n",
    "    'FilteredNoise.n_samples = {}'.format(n_samples),\n",
    "    'F0LoudnessPreprocessor.time_steps = {}'.format(time_steps),\n",
    "    'oscillator_bank.use_angular_cumsum = True',  # Avoids cumsum accumulation errors.\n",
    "]\n",
    "\n",
    "with gin.unlock_config():\n",
    "  gin.parse_config(gin_params)\n",
    "\n",
    "\n",
    "# Trim all input vectors to correct lengths \n",
    "for key in ['f0_hz', 'f0_confidence', 'loudness_db']:\n",
    "  audio_features[key] = audio_features[key][:time_steps]\n",
    "audio_features['audio'] = audio_features['audio'][:n_samples]\n",
    "\n",
    "# Set up the model just to predict audio given new conditioning\n",
    "model_z = ddsp.training.models.Autoencoder()\n",
    "model_z.restore(ckpt)\n",
    "\n",
    "# Resynthesize audio.\n",
    "\n",
    "outputs_z = model_z(audio_features, training=False) # Run the forward pass, add losses, and create a dictionary of outputs.\n",
    "\n",
    "# print(outputs.keys())\n",
    "# dict_keys(['inputs', 'audio', 'f0_hz', 'f0_confidence', 'loundness_db', \n",
    "#           'f0_condience', 'loudness_db', 'f0_scaled', 'ld_scaled', 'amps', \n",
    "#           'harmonic_distribution', 'noise_magnitudes', 'harmonic', 'filtered_noise', \n",
    "#           'add', 'reverb', 'out', 'audio_synth'])\n",
    "\n",
    "audio_gen_z = outputs_z['audio_synth']\n",
    "print(audio_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Resynthesis with z encoder')\n",
    "ipd.Audio(audio_gen_z, rate = sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.specplot(audio_gen_z)\n",
    "_ = plt.title(\"Resynthesis with z encoder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get feature z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_feature = outputs_z['z']\n",
    "print(np.shape(z_feature),'\\n',z_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UaLOL7hZZHav"
   },
   "source": [
    "## Comparing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Original')\n",
    "ipd.Audio(audio, rate = sample_rate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Resynthesis without z encoder')\n",
    "ipd.Audio(audio_gen, rate = sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Resynthesis with z encoder')\n",
    "ipd.Audio(audio_gen_z, rate = sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 971474,
     "status": "aborted",
     "timestamp": 1615370755684,
     "user": {
      "displayName": "Xinjian OUYANG",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgDmgUNu_vljWNL53AJFQvh-vkweabOtVRZoY3kWA=s64",
      "userId": "04586718377978961617"
     },
     "user_tz": -60
    },
    "id": "O83PMi_HlmLi",
    "outputId": "88070a53-5728-40cc-8df0-c5a051a93c10"
   },
   "outputs": [],
   "source": [
    "# Plot\n",
    "utils.specplot(audio)\n",
    "plt.title(\"Original\")\n",
    "\n",
    "utils.specplot(audio_gen)\n",
    "_ = plt.title(\"Resynthesis with z encoder\")\n",
    "\n",
    "utils.specplot(audio_gen_z)\n",
    "_ = plt.title(\"Resynthesis with z encoder\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "showing_models_local.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
