{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JXctfLGdacKx"
   },
   "source": [
    "Showing the DDSP models we have trained\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TUUGDMY5qSdz"
   },
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "m2Ol13FaZKwh"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-39aa5fed26a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Pôle projet Rennes_DDSP/DDSP小组资料/Pole_Projet_DDSP_Github/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mddsp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbase64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "# %tensorflow_version 2.x\n",
    "# !pip install -qU ddsp[data_preparation]==1.0.1\n",
    "\n",
    "# Ignore a bunch of deprecation warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import utils\n",
    "\n",
    "import os\n",
    "import ddsp\n",
    "import ddsp.training\n",
    "import gin\n",
    "import pickle\n",
    "\n",
    "import matplotlib\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import soundfile as sf \n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import librosa\n",
    "import librosa.display\n",
    "import tensorflow.compat.v2 as tf\n",
    "import tensorflow_datasets as tfds  \n",
    "\n",
    "%matplotlib inline\n",
    "sample_rate = 16000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gzUgnAjhrP9g"
   },
   "source": [
    "## Reading audios and computing (f0,loudness,z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lObag5Jd9amV"
   },
   "source": [
    "### Using the given [python file](https://github.com/magenta/ddsp/blob/master/ddsp/spectral_ops.py) in ddsp library to compute $f0$ and loudness.\n",
    "* *ddsp.spectral_ops.compute_f0*\n",
    "\n",
    "* *ddsp.spectral_ops.compute_loudness*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "executionInfo": {
     "elapsed": 570616,
     "status": "ok",
     "timestamp": 1615370354792,
     "user": {
      "displayName": "Xinjian OUYANG",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgDmgUNu_vljWNL53AJFQvh-vkweabOtVRZoY3kWA=s64",
      "userId": "04586718377978961617"
     },
     "user_tz": -60
    },
    "id": "jE5MqZnlMNNa",
    "outputId": "fc206f4f-689b-4efc-a04b-79d8f7d1b7d5"
   },
   "outputs": [],
   "source": [
    "x_all, sr = sf.read('./Pretraine_ models_for_T2/DDSP_saxophone_without_z/SAX.wav') #data,samplerate\n",
    "print('shape of original signal:',np.shape(x_all),'\\n','original sample rate:',sr)\n",
    "sig = x_all[:,0]\n",
    " \n",
    "# resample (down sampling to 16kHz) and take the first 10 seconds\n",
    "sig_re = librosa.resample(sig,sr,sample_rate)\n",
    "# print(sig_re)\n",
    "audio = sig_re[:10*sample_rate]\n",
    "print('audio shape:',np.shape(audio))\n",
    "#audio = audio[np.newaxis,:]\n",
    "\n",
    "# plot wave form\n",
    "T_all = audio.shape[0]\n",
    "time = np.arange(T_all)/sample_rate\n",
    "plt.figure(figsize=(9,3))\n",
    "plt.plot(time, audio)\n",
    "plt.xlabel('time (s)')\n",
    "plt.ylabel('amplitude')\n",
    "\n",
    "# play audio\n",
    "#utils.play(audio) \n",
    "ipd.Audio(audio, rate = sample_rate)\n",
    "\n",
    "# Calculate Spectrogram and plot\n",
    "utils.specplot(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 778
    },
    "executionInfo": {
     "elapsed": 17211,
     "status": "ok",
     "timestamp": 1615371220642,
     "user": {
      "displayName": "Xinjian OUYANG",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgDmgUNu_vljWNL53AJFQvh-vkweabOtVRZoY3kWA=s64",
      "userId": "04586718377978961617"
     },
     "user_tz": -60
    },
    "id": "0gOzm3pp7vQb",
    "outputId": "928aa139-c5d3-4f66-843f-672db3051b51"
   },
   "outputs": [],
   "source": [
    "#extracting f0 with CREPE\n",
    "ddsp.spectral_ops.reset_crepe()\n",
    "f0_crepe, f0_confidence = ddsp.spectral_ops.compute_f0(audio, \n",
    "                                                       sample_rate= sample_rate,\n",
    "                                                       frame_rate=31.25,\n",
    "                                                       viterbi=False)\n",
    "#extracting loudness \n",
    "loudness =ddsp.spectral_ops.compute_loudness(audio,\n",
    "                     sample_rate= sample_rate,\n",
    "                     frame_rate=250,\n",
    "                     n_fft=2048,\n",
    "                     ref_db=20.7,\n",
    "                     use_tf=False)\n",
    "\n",
    "audio_features_key = ['audio','f0_hz','f0_confidence','loundness_db']\n",
    "audio_features = dict([(k,[]) for k in audio_features_key])\n",
    "audio_features['audio'] = audio\n",
    "audio_features['f0_hz'] = f0_crepe\n",
    "audio_features['f0_condience'] = f0_confidence\n",
    "audio_features['loudness_db'] = loudness\n",
    "\n",
    "\n",
    "# Plot Pitch/f0.\n",
    "plt.figure(figsize=(6, 4))\n",
    "f0_crepe_midi = ddsp.core.hz_to_midi(f0_crepe)\n",
    "plt.plot(np.ravel(audio_features['f0_hz']), label='crepe')\n",
    "plt.ylabel('Pitch (MIDI)')\n",
    "# Plot f0_confidence.\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(np.ravel(audio_features['f0_condience']), label='f0 confidence')\n",
    "plt.ylabel('f0 confidence')\n",
    "# Plot Loundness.\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(np.ravel(audio_features['loudness_db']), label='loudness')\n",
    "plt.ylabel('Loudness')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YnXqvk-CVxGL"
   },
   "source": [
    "### Compute z/MFCC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SJugSlvbVVUx"
   },
   "source": [
    "* training withou z encoder [solo_instrument.gin](https://github.com/magenta/ddsp/blob/master/ddsp/training/gin/models/solo_instrument.gin)\n",
    "* training with z encoder [ae.gin](https://github.com/magenta/ddsp/blob/master/ddsp/training/gin/models/ae.gin)\n",
    "\n",
    "**z-encoder**: the encoder ﬁrst calculates MFCC’s (Mel Frequency Cepstrum Coefﬁcients) from the audio. MFCC is computed from the log-mel-spectrogram of the audio with a FFT size of 1024, 128 bins of frequency range between 20Hz to 8000Hz, overlap of 75%. We use only the ﬁrst 30 MFCCs that correspond to a smoothed spectral envelope. The MFCCs are then passed through a normalization layer (which has learnable shift and scale parameters) and a 512-unit GRU. The GRU outputs (over time) fed to a 512-unit linear layer to obtain z(t). The z embedding reported in this model has 16 dimensions across 250 time-steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dl6b1J5ZC2CN"
   },
   "source": [
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1E-KntALWa0_fFSwL2JaJicEPv2yif7Zz\" alt=\"Diagram of the z-encoder\" width=\"700\">\n",
    "\n",
    "* [z encoder](https://github.com/magenta/ddsp/blob/master/ddsp/training/encoders.py) and [MFCC computing file](https://github.com/magenta/ddsp/blob/master/ddsp/spectral_ops.py) in DDSP library\n",
    "* *ddsp.spectral_ops.compute_mfcc*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 500
    },
    "executionInfo": {
     "elapsed": 1171,
     "status": "ok",
     "timestamp": 1615371245992,
     "user": {
      "displayName": "Xinjian OUYANG",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgDmgUNu_vljWNL53AJFQvh-vkweabOtVRZoY3kWA=s64",
      "userId": "04586718377978961617"
     },
     "user_tz": -60
    },
    "id": "FE-TKlVSC8B5",
    "outputId": "57afbd24-7540-4686-932d-9a7e0fb50a8e"
   },
   "outputs": [],
   "source": [
    "#Calculate MFCC(Mel-frequency Cepstral Coefficients)\n",
    "mfccs = ddsp.spectral_ops.compute_mfcc(\n",
    "    audio,\n",
    "    lo_hz=20.0,\n",
    "    hi_hz=8000.0,\n",
    "    fft_size=1024,\n",
    "    mel_bins=128,\n",
    "    mfcc_bins=30)\n",
    "\n",
    "# Plot MFCC.\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(np.ravel(mfccs), label='MFCC')\n",
    "plt.ylabel('MFCC')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PQThLZ17mW7V"
   },
   "source": [
    "### Another way to compute f0 and loudness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dimxak_jk1e2"
   },
   "outputs": [],
   "source": [
    "# # Setup the session.\n",
    "# ddsp.spectral_ops.reset_crepe()\n",
    "\n",
    "# # Compute features.\n",
    "# audio_features = ddsp.training.metrics.compute_audio_features(audio)\n",
    "# audio_features['loudness_db'] = audio_features['loudness_db'].astype(np.float32)\n",
    "# audio_features_mod = None\n",
    "\n",
    "# TRIM = -15\n",
    "# # Plot Features.\n",
    "# fig, ax = plt.subplots(nrows=3, \n",
    "#                        ncols=1, \n",
    "#                        sharex=True,\n",
    "#                        figsize=(6, 8))\n",
    "# ax[0].plot(audio_features['loudness_db'][:TRIM])\n",
    "# ax[0].set_ylabel('loudness_db')\n",
    "\n",
    "# ax[1].plot(librosa.hz_to_midi(audio_features['f0_hz'][:TRIM]))\n",
    "# ax[1].set_ylabel('f0 [midi]')\n",
    "\n",
    "# ax[2].plot(audio_features['f0_confidence'][:TRIM])\n",
    "# ax[2].set_ylabel('f0 confidence')\n",
    "# _ = ax[2].set_xlabel('Time step [frame]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yQ_iCEY5s9Mc"
   },
   "source": [
    "## Load the model(without z encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AhJuY90m0lX1"
   },
   "source": [
    "### set paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hE0_4cJQ0lX1"
   },
   "outputs": [],
   "source": [
    "# model folder direction \n",
    "model_dir = 'Pretraine_ models_for_T2/DDSP_saxophone_without_z/my_solo_instrument'\n",
    "\n",
    "# dataset_statistics.pkl in .model folder\n",
    "dataset_stats_file = os.path.join(model_dir, 'dataset_statistics.pkl')\n",
    "\n",
    "# operative_config-0.gin in model folder\n",
    "gin_file = os.path.join(model_dir, 'operative_config-0.gin')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M4K4tMff0lX2"
   },
   "source": [
    "### load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 971476,
     "status": "aborted",
     "timestamp": 1615370755682,
     "user": {
      "displayName": "Xinjian OUYANG",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgDmgUNu_vljWNL53AJFQvh-vkweabOtVRZoY3kWA=s64",
      "userId": "04586718377978961617"
     },
     "user_tz": -60
    },
    "id": "ra1EW2eMAcT5",
    "outputId": "e608c269-3e6d-4146-d5b6-214c88077fa5"
   },
   "outputs": [],
   "source": [
    "# Load the dataset statistics.\n",
    "print(f'Loading dataset statistics from {dataset_stats_file}')\n",
    "try:\n",
    "  if tf.io.gfile.exists(dataset_stats_file):\n",
    "    with tf.io.gfile.GFile(dataset_stats_file, 'rb') as f:\n",
    "      DATASET_STATS = pickle.load(f)\n",
    "except Exception as err:\n",
    "  print('Loading dataset statistics from pickle failed: {}.'.format(err))\n",
    "\n",
    "\n",
    "# Parse gin config,\n",
    "with gin.unlock_config():\n",
    "  gin.parse_config_file(gin_file, skip_unknown=True)\n",
    "\n",
    "# Assumes only one checkpoint in the folder, 'ckpt-[iter]`.\n",
    "ckpt_files = [f for f in tf.io.gfile.listdir(model_dir) if 'ckpt' in f]\n",
    "ckpt_name = ckpt_files[0].split('.')[0]\n",
    "ckpt = os.path.join(model_dir, ckpt_name)\n",
    "\n",
    "# Ensure dimensions and sampling rates are equal\n",
    "time_steps_train = gin.query_parameter('F0LoudnessPreprocessor.time_steps')\n",
    "n_samples_train = gin.query_parameter('Harmonic.n_samples')\n",
    "hop_size = int(n_samples_train / time_steps_train)\n",
    "\n",
    "time_steps = int(audio.shape[0] / hop_size)\n",
    "n_samples = time_steps * hop_size\n",
    "\n",
    "# print(\"===Trained model===\")\n",
    "# print(\"Time Steps\", time_steps_train)\n",
    "# print(\"Samples\", n_samples_train)\n",
    "# print(\"Hop Size\", hop_size)\n",
    "# print(\"\\n===Resynthesis===\")\n",
    "# print(\"Time Steps\", time_steps)\n",
    "# print(\"Samples\", n_samples)\n",
    "# print('')\n",
    "\n",
    "gin_params = [\n",
    "    'Harmonic.n_samples = {}'.format(n_samples),\n",
    "    'FilteredNoise.n_samples = {}'.format(n_samples),\n",
    "    'F0LoudnessPreprocessor.time_steps = {}'.format(time_steps),\n",
    "    'oscillator_bank.use_angular_cumsum = True',  # Avoids cumsum accumulation errors.\n",
    "]\n",
    "\n",
    "with gin.unlock_config():\n",
    "  gin.parse_config(gin_params)\n",
    "\n",
    "\n",
    "# Trim all input vectors to correct lengths \n",
    "for key in ['f0_hz', 'f0_confidence', 'loudness_db']:\n",
    "  audio_features[key] = audio_features[key][:time_steps]\n",
    "audio_features['audio'] = audio_features['audio'][:n_samples]\n",
    "\n",
    "\n",
    "# Set up the model just to predict audio given new conditioning\n",
    "model = ddsp.training.models.Autoencoder()\n",
    "model.restore(ckpt)\n",
    "\n",
    "# Resynthesize audio.\n",
    "outputs = model(audio_features, training=False) # Run the forward pass, add losses, and create a dictionary of outputs.\n",
    "# print(outputs.keys())\n",
    "# dict_keys(['inputs', 'audio', 'f0_hz', 'f0_confidence', 'loundness_db', \n",
    "#           'f0_condience', 'loudness_db', 'f0_scaled', 'ld_scaled', 'amps', \n",
    "#           'harmonic_distribution', 'noise_magnitudes', 'harmonic', 'filtered_noise', \n",
    "#           'add', 'reverb', 'out', 'audio_synth'])\n",
    "\n",
    "audio_gen = outputs['audio_synth']\n",
    "#print(audio_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the model(with z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model folder direction \n",
    "model_dir_z = 'Pretraine_ models_for_T2/DDSP_saxophone_with_z/my_solo_instrument_using_ae'\n",
    "\n",
    "# dataset_statistics.pkl in .model folder\n",
    "dataset_stats_file_z = os.path.join(model_dir_z, 'dataset_statistics.pkl')\n",
    "\n",
    "# operative_config-0.gin in model folder\n",
    "gin_file_z = os.path.join(model_dir_z, 'operative_config-0.gin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset statistics.\n",
    "print(f'Loading dataset statistics from {dataset_stats_file}')\n",
    "try:\n",
    "  if tf.io.gfile.exists(dataset_stats_file):\n",
    "    with tf.io.gfile.GFile(dataset_stats_file, 'rb') as f:\n",
    "      DATASET_STATS = pickle.load(f)\n",
    "except Exception as err:\n",
    "  print('Loading dataset statistics from pickle failed: {}.'.format(err))\n",
    "\n",
    "\n",
    "# Parse gin config,\n",
    "with gin.unlock_config():\n",
    "  gin.parse_config_file(gin_file_z, skip_unknown=True)\n",
    "\n",
    "# Assumes only one checkpoint in the folder, 'ckpt-[iter]`.\n",
    "ckpt_files = [f for f in tf.io.gfile.listdir(model_dir_z) if 'ckpt' in f]\n",
    "ckpt_name = ckpt_files[0].split('.')[0]\n",
    "ckpt = os.path.join(model_dir_z, ckpt_name)\n",
    "\n",
    "# Ensure dimensions and sampling rates are equal\n",
    "time_steps_train = gin.query_parameter('F0LoudnessPreprocessor.time_steps')\n",
    "n_samples_train = gin.query_parameter('Harmonic.n_samples')\n",
    "hop_size = int(n_samples_train / time_steps_train)\n",
    "\n",
    "time_steps = int(audio.shape[0] / hop_size)\n",
    "n_samples = time_steps * hop_size\n",
    "\n",
    "# print(\"===Trained model===\")\n",
    "# print(\"Time Steps\", time_steps_train)\n",
    "# print(\"Samples\", n_samples_train)\n",
    "# print(\"Hop Size\", hop_size)\n",
    "# print(\"\\n===Resynthesis===\")\n",
    "# print(\"Time Steps\", time_steps)\n",
    "# print(\"Samples\", n_samples)\n",
    "# print('')\n",
    "\n",
    "gin_params = [\n",
    "    'Harmonic.n_samples = {}'.format(n_samples),\n",
    "    'FilteredNoise.n_samples = {}'.format(n_samples),\n",
    "    'F0LoudnessPreprocessor.time_steps = {}'.format(time_steps),\n",
    "    'oscillator_bank.use_angular_cumsum = True',  # Avoids cumsum accumulation errors.\n",
    "]\n",
    "\n",
    "with gin.unlock_config():\n",
    "  gin.parse_config(gin_params)\n",
    "\n",
    "\n",
    "# Trim all input vectors to correct lengths \n",
    "for key in ['f0_hz', 'f0_confidence', 'loudness_db']:\n",
    "  audio_features[key] = audio_features[key][:time_steps]\n",
    "audio_features['audio'] = audio_features['audio'][:n_samples]\n",
    "\n",
    "\n",
    "# Set up the model just to predict audio given new conditioning\n",
    "model_z = ddsp.training.models.Autoencoder()\n",
    "model_z.restore(ckpt)\n",
    "\n",
    "# Resynthesize audio.\n",
    "outputs_z = model(audio_features, training=False) # Run the forward pass, add losses, and create a dictionary of outputs.\n",
    "# print(outputs.keys())\n",
    "# dict_keys(['inputs', 'audio', 'f0_hz', 'f0_confidence', 'loundness_db', \n",
    "#           'f0_condience', 'loudness_db', 'f0_scaled', 'ld_scaled', 'amps', \n",
    "#           'harmonic_distribution', 'noise_magnitudes', 'harmonic', 'filtered_noise', \n",
    "#           'add', 'reverb', 'out', 'audio_synth'])\n",
    "\n",
    "audio_gen_z = outputs_z['audio_synth']\n",
    "#print(audio_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UaLOL7hZZHav"
   },
   "source": [
    "## Comparing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 971474,
     "status": "aborted",
     "timestamp": 1615370755684,
     "user": {
      "displayName": "Xinjian OUYANG",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgDmgUNu_vljWNL53AJFQvh-vkweabOtVRZoY3kWA=s64",
      "userId": "04586718377978961617"
     },
     "user_tz": -60
    },
    "id": "O83PMi_HlmLi",
    "outputId": "88070a53-5728-40cc-8df0-c5a051a93c10"
   },
   "outputs": [],
   "source": [
    "# Plot\n",
    "print('Original')\n",
    "ipd.Audio(audio, rate = sample_rate) \n",
    "utils.specplot(audio)\n",
    "plt.title(\"Original\")\n",
    "\n",
    "print('Resynthesis without z encoder')\n",
    "ipd.Audio(audio_gen, rate = sample_rate)\n",
    "utils.specplot(audio_gen)\n",
    "_ = plt.title(\"Resynthesis with z encoder\")\n",
    "\n",
    "print('Resynthesis with z encoder')\n",
    "ipd.Audio(audio_gen_z, rate = sample_rate)\n",
    "utils.specplot(audio_gen_z)\n",
    "_ = plt.title(\"Resynthesis with z encoder\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "showing_models_local.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
