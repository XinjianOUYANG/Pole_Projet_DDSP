{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a model without z encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please put your audio files in the folder  *./Pretrained_ Models_for_T2/training_solo*\n",
    "\n",
    "### If the training process is termineated, rerun the sections \"Import dependencies\",\"Set paths\" and \"Train model\" sequentially to continue training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import ddsp.training\n",
    "from matplotlib import pyplot as plt\n",
    "import IPython.display as ipd\n",
    "import gin\n",
    "import numpy as np\n",
    "import utils\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline\n",
    "sample_rate = 16000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DRIVE_DIR = './Pretrained_Models_for_T2/training_solo'  \n",
    "assert os.path.exists(DRIVE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qd22WxEQI3FV"
   },
   "outputs": [],
   "source": [
    "# create all directories leading up to the given directory that do not exist already. \n",
    "# If the given directory already exists, ignore the error.\n",
    "DATA_DIR = os.path.join(DRIVE_DIR, 'data')\n",
    "!mkdir -p \"$DATA_DIR\"\n",
    "AUDIO_DIR = os.path.join(DATA_DIR, 'audio')\n",
    "AUDIO_FILEPATTERN = AUDIO_DIR + '/*'\n",
    "!mkdir -p \"$AUDIO_DIR\"\n",
    "# folder to save the model\n",
    "SAVE_DIR = os.path.join(DRIVE_DIR, 'ddsp-solo-instrument')\n",
    "!mkdir -p \"$SAVE_DIR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# record the training data\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, 'train')\n",
    "!mkdir -p \"$TRAIN_DIR\"\n",
    "TRAIN_TFRECORD = TRAIN_DIR + '/train.tfrecord'\n",
    "TRAIN_TFRECORD_FILEPATTERN = TRAIN_DIR + '/train.tfrecord*'\n",
    "print(TRAIN_TFRECORD_FILEPATTERN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fb4YD8woYD1H"
   },
   "source": [
    "## Prepare Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "itVKEzF6m3rY"
   },
   "outputs": [],
   "source": [
    "mp3_files = glob.glob(os.path.join(DRIVE_DIR, '*.mp3'))\n",
    "wav_files = glob.glob(os.path.join(DRIVE_DIR, '*.wav'))\n",
    "audio_files = mp3_files + wav_files\n",
    "\n",
    "for fname in audio_files:\n",
    "  target_name = os.path.join(AUDIO_DIR, \n",
    "                             os.path.basename(fname).replace(' ', '_'))\n",
    "  print('Copying {} to {}'.format(fname, target_name))\n",
    "  !cp \"$fname\" \"$target_name\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to do some preprocessing on the raw audio you uploaded to get it into the correct format for training. This involves turning the full audio into short (4-second) examples, inferring the fundamental frequency (or \"pitch\") with [CREPE](http://github.com/marl/crepe), and computing the loudness. **These features will then be stored in a sharded [TFRecord](https://www.tensorflow.org/tutorials/load_data/tfrecord) file for easier loading. Depending on the amount of input audio, this process usually takes a few minutes**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ddsp_prepare_tfrecord \\\n",
    "--input_audio_filepatterns=\"$AUDIO_FILEPATTERN \"\\\n",
    "--output_tfrecord_path=\"$TRAIN_TFRECORD\" \\\n",
    "--num_shards=10 \\\n",
    "--alsologtostderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bp_c8P0xApY6"
   },
   "outputs": [],
   "source": [
    "data_provider = ddsp.training.data.TFRecordProvider(TRAIN_TFRECORD_FILEPATTERN)\n",
    "dataset = data_provider.get_dataset(shuffle=False)\n",
    "PICKLE_FILE_PATH = os.path.join(SAVE_DIR, 'dataset_statistics.pkl')\n",
    "\n",
    "utils.save_dataset_statistics(data_provider, PICKLE_FILE_PATH, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nIsq0HrzbOF7"
   },
   "source": [
    "Let's load the dataset in the `ddsp` library and have a look at one of the examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dA-FOmRgYdpZ"
   },
   "outputs": [],
   "source": [
    "data_provider = ddsp.training.data.TFRecordProvider(TRAIN_TFRECORD_FILEPATTERN)\n",
    "dataset = data_provider.get_dataset(shuffle=False)\n",
    "\n",
    "try:\n",
    "  ex = next(iter(dataset))\n",
    "except StopIteration:\n",
    "  raise ValueError(\n",
    "      'TFRecord contains no examples. Please try re-running the pipeline with '\n",
    "      'different audio file(s).')\n",
    "\n",
    "utils.specplot(ex['audio'])\n",
    "\n",
    "f, ax = plt.subplots(3, 1, figsize=(14, 4))\n",
    "x = np.linspace(0, 4.0, 1000)\n",
    "ax[0].set_ylabel('loudness_db')\n",
    "ax[0].plot(x, ex['loudness_db'])\n",
    "ax[1].set_ylabel('F0_Hz')\n",
    "ax[1].set_xlabel('seconds')\n",
    "ax[1].plot(x, ex['f0_hz'])\n",
    "ax[2].set_ylabel('F0_confidence')\n",
    "ax[2].set_xlabel('seconds')\n",
    "ax[2].plot(x, ex['f0_confidence'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(ex['audio'], rate = sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9gvXBa7PbuyY"
   },
   "source": [
    "## Train Model\n",
    "\n",
    "We will now train a \"solo instrument\" model. This means the model is conditioned only on the fundamental frequency (f0) and loudness with no instrument ID or latent timbre feature. If you uploaded audio of multiple instruemnts, the neural network you train will attempt to model all timbres, but will likely associate certain timbres with different f0 and loudness conditions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u2lx7yJneUXT"
   },
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "import tensorboard as tb\n",
    "tb.notebook.start('--logdir \"{}\"'.format(SAVE_DIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fT-8Koyvj46w"
   },
   "source": [
    "### We will now begin training. \n",
    "\n",
    "Note that we specify [gin configuration](https://github.com/google/gin-config) files for the both the model architecture ([solo_instrument.gin](TODO)) and the dataset ([tfrecord.gin](TODO)), which are both predefined in the library. You could also create your own. We then override some of the spefic params for `batch_size` (which is defined in in the model gin file) and the tfrecord path (which is defined in the dataset file). \n",
    "\n",
    "### Training Notes:\n",
    "\n",
    "* Models typically perform well when the loss drops to the range of ~4.5-5.0.\n",
    "* Depending on the dataset this can take anywhere from 5k-30k training steps usually.\n",
    "* The default is set to 30k, but you can stop training at any time, and for timbre transfer, it's best to stop before the loss drops too far below ~5.0 to avoid overfitting.\n",
    "* On the colab GPU, this can take from around 3-20 hours. \n",
    "* We **highly recommend** saving checkpoints directly to your drive account as colab will restart naturally after about 12 hours and you may lose all of your checkpoints.\n",
    "* By default, checkpoints will be saved every 300 steps with a maximum of 10 checkpoints (at ~60MB/checkpoint this is ~600MB). Feel free to adjust these numbers depending on the frequency of saves you would like and space on your drive.\n",
    "* If you're restarting a session and `DRIVE_DIR` points a directory that was previously used for training, training should resume at the last checkpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### if you change the path at the begining of the notebook, your must replace the path './Pretrained_ Models_for_T2/training_solo/data/train/train.tfrecord*' by the following print "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(TRAIN_TFRECORD_FILEPATTERN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "poKO-mZEGYXZ"
   },
   "outputs": [],
   "source": [
    "!ddsp_run \\\n",
    "  --mode=train \\\n",
    "  --alsologtostderr \\\n",
    "  --save_dir=\"$SAVE_DIR\" \\\n",
    "  --gin_file=models/solo.gin \\\n",
    "  --gin_file=datasets/tfrecord.gin \\\n",
    "  --gin_param=\"TFRecordProvider.file_pattern='./Pretrained_Models_for_T2/training_solo/data/train/train.tfrecord*'\"\\\n",
    "  --gin_param=\"batch_size=16\" \\\n",
    "  --gin_param=\"train_util.train.num_steps=30000\" \\\n",
    "  --gin_param=\"train_util.train.steps_per_save=400\" \\\n",
    "  --gin_param=\"trainers.Trainer.checkpoints_to_keep=10\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V95qxVjFzWR6"
   },
   "source": [
    "## Resynthesis\n",
    "\n",
    "Check how well the model reconstructs the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OQ5PPDZVzgFR"
   },
   "outputs": [],
   "source": [
    "data_provider = ddsp.training.data.TFRecordProvider(TRAIN_TFRECORD_FILEPATTERN)\n",
    "dataset = data_provider.get_batch(batch_size=1, shuffle=False)\n",
    "\n",
    "try:\n",
    "  batch = next(iter(dataset))\n",
    "except OutOfRangeError:\n",
    "  raise ValueError(\n",
    "      'TFRecord contains no examples. Please try re-running the pipeline with '\n",
    "      'different audio file(s).')\n",
    "\n",
    "# Parse the gin config.\n",
    "gin_file = os.path.join(SAVE_DIR, 'operative_config-0.gin')\n",
    "gin.parse_config_file(gin_file)\n",
    "\n",
    "# Load model\n",
    "model = ddsp.training.models.Autoencoder()\n",
    "model.restore(SAVE_DIR)\n",
    "\n",
    "# Resynthesize audio.\n",
    "outputs = model(batch, training=False)\n",
    "audio_gen = model.get_audio_from_outputs(outputs)\n",
    "audio = batch['audio']\n",
    "\n",
    "print('Original Audio')\n",
    "utils.specplot(audio)\n",
    "\n",
    "print('Resynthesis')\n",
    "utils.specplot(audio_gen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Original Audio')\n",
    "ipd.Audio(audio[0], rate = sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Resynthesis')\n",
    "ipd.Audio(audio_gen[0], rate = sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZXM2ynLQ2Wl3"
   },
   "source": [
    "## SAVE Checkpoint\n",
    "\n",
    "Below you can download the final checkpoint. You are now ready to use it in the [DDSP Timbre Tranfer Colab](https://colab.research.google.com/github/magenta/ddsp/blob/master/ddsp/colab/demos/timbre_transfer.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2WDiCyXP0tNE"
   },
   "outputs": [],
   "source": [
    "CHECKPOINT_ZIP = 'my_solo_instrument.zip'\n",
    "latest_checkpoint_fname = os.path.basename(tf.train.latest_checkpoint(SAVE_DIR))\n",
    "!cd \"$SAVE_DIR\" && zip $CHECKPOINT_ZIP $latest_checkpoint_fname* operative_config-0.gin dataset_statistics.pkl\n",
    "!cp \"$SAVE_DIR/$CHECKPOINT_ZIP\" ./ "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "hMqWDc_m6rUC"
   ],
   "name": "train_autoencoder.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
