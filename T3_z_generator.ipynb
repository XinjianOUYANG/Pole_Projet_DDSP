{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "broadband-cornell",
   "metadata": {},
   "source": [
    "# Generate z datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formal-theory",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "floating-excerpt",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Argument whitelist is deprecated. Please use allowlist.\n"
     ]
    }
   ],
   "source": [
    "# Ignore a bunch of deprecation warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import tensorflow.compat.v2 as tf\n",
    "import tensorflow_datasets as tfds \n",
    "import ddsp\n",
    "import utils\n",
    "import os\n",
    "import gin\n",
    "import pickle\n",
    "import matplotlib\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import soundfile as sf \n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import librosa\n",
    "import librosa.display\n",
    " \n",
    "%matplotlib inline\n",
    "sample_rate = 16000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honey-requirement",
   "metadata": {},
   "source": [
    "## Setting the path of audios and model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improved-trinity",
   "metadata": {},
   "source": [
    "### Model path with z encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "artistic-administrator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained_Models_for_T2/piano_ae \n",
      " Pretrained_Models_for_T2/piano_ae/dataset_statistics.pkl \n",
      " Pretrained_Models_for_T2/piano_ae/operative_config-0.gin\n",
      "find checkpoint: Pretrained_Models_for_T2/piano_ae/ckpt-8400\n"
     ]
    }
   ],
   "source": [
    "# model folder direction \n",
    "model_dir_z = 'Pretrained_Models_for_T2/piano_ae'\n",
    "model_name = os.path.basename(model_dir_z)\n",
    "\n",
    "# dataset_statistics.pkl in .model folder\n",
    "dataset_stats_file_z = os.path.join(model_dir_z, 'dataset_statistics.pkl')\n",
    "\n",
    "# operative_config-0.gin in model folder\n",
    "gin_file_z = os.path.join(model_dir_z, 'operative_config-0.gin')\n",
    "\n",
    "# Assumes only one checkpoint in the folder, 'ckpt-[iter]`.\n",
    "ckpt_files = [f for f in tf.io.gfile.listdir(model_dir_z) if 'ckpt' in f]\n",
    "ckpt_name = ckpt_files[0].split('.')[0]\n",
    "ckpt = os.path.join(model_dir_z, ckpt_name)\n",
    "\n",
    "print(model_dir_z,'\\n',dataset_stats_file_z,'\\n',gin_file_z)\n",
    "print('find checkpoint:',ckpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satisfactory-disaster",
   "metadata": {},
   "source": [
    "### Audio directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "spread-poison",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Datasets/Piano/Audio/Piano_01.wav', 'Datasets/Piano/Audio/Piano_02.wav', 'Datasets/Piano/Audio/Piano_03.wav', 'Datasets/Piano/Audio/Piano_04.wav', 'Datasets/Piano/Audio/Piano_05.wav', 'Datasets/Piano/Audio/Piano_06.wav', 'Datasets/Piano/Audio/Piano_07.wav', 'Datasets/Piano/Audio/Piano_08.wav', 'Datasets/Piano/Audio/Piano_09.wav', 'Datasets/Piano/Audio/Piano_10.wav', 'Datasets/Piano/Audio/Piano_11.wav', 'Datasets/Piano/Audio/Piano_12.wav', 'Datasets/Piano/Audio/Piano_13.wav', 'Datasets/Piano/Audio/Piano_14.wav', 'Datasets/Piano/Audio/Piano_15.wav']\n",
      "\n",
      " number of audios: 15\n"
     ]
    }
   ],
   "source": [
    "# audio directory path\n",
    "audio_dir = 'Datasets/Piano/Audio'\n",
    "audio_folder = []\n",
    "\n",
    "files = os.listdir(audio_dir)\n",
    "for tmp in files:\n",
    "    if os.path.splitext(tmp)[1] == '.wav' or os.path.splitext(tmp)[1] == '.mp3': \n",
    "        audio_folder.append(os.path.join(audio_dir,tmp))\n",
    "\n",
    "audio_folder.sort()\n",
    "print(audio_folder)\n",
    "audio_num = len(audio_folder)\n",
    "print('\\n number of audios:', audio_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accomplished-prospect",
   "metadata": {},
   "source": [
    "## Load the model\n",
    "\n",
    "We use utils.model_loading function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amazing-instrumentation",
   "metadata": {},
   "source": [
    "## Generate z datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raised-blood",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_datasets = np.zeros(shape=(audio_num,1,15000,16)) # shape of z =(1, frame_rate*length_audio, 16)\n",
    "\n",
    "i = 0\n",
    "for audio_path in audio_folder:\n",
    "    print('processing the audio',i+1,'/',audio_num,':',audio_path)\n",
    "    \n",
    "    x_all, sr = sf.read(audio_path) #data,samplerate\n",
    "    #print('shape of original signal:',np.shape(x_all),'\\n','original sample rate:',sr)\n",
    "    sig = x_all[:] # choose the first channel of the original audio\n",
    "\n",
    "    # resample (down sampling to 16kHz) and take the 10-20 seconds\n",
    "    sig_re = librosa.resample(sig,sr,sample_rate)\n",
    "    audio = sig_re#[10*sample_rate:30*sample_rate]\n",
    "    #print('audio shape:',np.shape(audio))\n",
    "    audio = audio[np.newaxis,:]\n",
    "\n",
    "    #extracting f0 with CREPE\n",
    "    ddsp.spectral_ops.reset_crepe()\n",
    "    f0_crepe, f0_confidence = ddsp.spectral_ops.compute_f0(audio[0], \n",
    "                                                           sample_rate= sample_rate,\n",
    "                                                           frame_rate=250,\n",
    "                                                           viterbi=False)\n",
    "    #extracting loudness \n",
    "    loudness =ddsp.spectral_ops.compute_loudness(audio[0],\n",
    "                         sample_rate= sample_rate,\n",
    "                         frame_rate=250,\n",
    "                         n_fft=2048,\n",
    "                         ref_db=20.7,\n",
    "                         use_tf=False)\n",
    "\n",
    "    # audio_features dictionary\n",
    "    audio_features_key = ['audio','f0_hz','f0_confidence','loudness_db']\n",
    "    audio_features = dict([(k,[]) for k in audio_features_key])\n",
    "    audio_features['audio'] = audio\n",
    "    audio_features['f0_hz'] = f0_crepe\n",
    "    audio_features['f0_confidence'] = f0_confidence\n",
    "    audio_features['loudness_db'] = loudness\n",
    "    \n",
    "    \n",
    "    # get z feature of the audio\n",
    "    outputs = utils.model_loading(audio, audio_features, model_dir, training = False) # Run the forward pass, add losses, and create a dictionary of outputs.\n",
    "    z_feature = outputs['z']\n",
    "    print('shape of z feature',np.shape(z_feature))\n",
    "    z_datasets[i] = z_feature\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specified-overall",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outputs.keys())\n",
    "# print()\n",
    "audio_gen = model.get_audio_from_outputs(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorrect-contents",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(audio_gen))\n",
    "print(audio_features)\n",
    "print(audio_features.keys())\n",
    "print(audio_features['audio'],np.shape(audio_features['audio']))\n",
    "\n",
    "print(np.shape(audio_features['f0_hz']))\n",
    "print(np.shape(outputs['f0_hz']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "auburn-arkansas",
   "metadata": {},
   "source": [
    "### Save z datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appreciated-labor",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = './z_datasets/z_' + model_name + '.npy'\n",
    "print(save_path)\n",
    "np.save(save_path, z_datasets)\n",
    "print(np.shape(z_datasets),'\\n')\n",
    "#print(z_datasets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
