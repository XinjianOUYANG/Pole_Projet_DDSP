{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "powerful-madonna",
   "metadata": {},
   "source": [
    "## Generate z datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tight-african",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focused-reggae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore a bunch of deprecation warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import tensorflow.compat.v2 as tf\n",
    "import tensorflow_datasets as tfds \n",
    "import ddsp\n",
    "import utils\n",
    "import os\n",
    "import gin\n",
    "import pickle\n",
    "import matplotlib\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import soundfile as sf \n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import librosa\n",
    "import librosa.display\n",
    " \n",
    "%matplotlib inline\n",
    "sample_rate = 16000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuck-killing",
   "metadata": {},
   "source": [
    "## Setting the path of audios and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic-glossary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio directory path\n",
    "audio_dir = 'Datasets/Piano/Audio'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "copyrighted-production",
   "metadata": {},
   "source": [
    "### Model path with z encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competent-genesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model folder direction \n",
    "model_dir_z = 'Pretrained_Models_for_T2/piano_ae'\n",
    "\n",
    "# dataset_statistics.pkl in .model folder\n",
    "dataset_stats_file_z = os.path.join(model_dir_z, 'dataset_statistics.pkl')\n",
    "\n",
    "# operative_config-0.gin in model folder\n",
    "gin_file_z = os.path.join(model_dir_z, 'operative_config-0.gin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extra-absorption",
   "metadata": {},
   "source": [
    "## Preprocess audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banned-cooper",
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_features(audio):\n",
    "    x_all, sr = sf.read(audio_path) #data,samplerate\n",
    "    print('shape of original signal:',np.shape(x_all),'\\n','original sample rate:',sr)\n",
    "    sig = x_all[:] # choose the first channel of the original audio\n",
    "\n",
    "    # resample (down sampling to 16kHz)\n",
    "    audio = librosa.resample(sig,sr,sample_rate)\n",
    "    print('audio shape:',np.shape(audio))\n",
    "    audio = audio[np.newaxis,:]\n",
    "\n",
    "    #extracting f0 with CREPE\n",
    "    ddsp.spectral_ops.reset_crepe()\n",
    "    f0_crepe, f0_confidence = ddsp.spectral_ops.compute_f0(audio[0], \n",
    "                                                           sample_rate= sample_rate,\n",
    "                                                           frame_rate=31.25,\n",
    "                                                           viterbi=False)\n",
    "    #extracting loudness \n",
    "    loudness =ddsp.spectral_ops.compute_loudness(audio[0],\n",
    "                         sample_rate= sample_rate,\n",
    "                         frame_rate=250,\n",
    "                         n_fft=2048,\n",
    "                         ref_db=20.7,\n",
    "                         use_tf=False)\n",
    "\n",
    "    # audio_features dictionary\n",
    "    audio_features_key = ['audio','f0_hz','f0_confidence','loundness_db']\n",
    "    audio_features = dict([(k,[]) for k in audio_features_key])\n",
    "    audio_features['audio'] = audio\n",
    "    audio_features['f0_hz'] = f0_crepe\n",
    "    audio_features['f0_confidence'] = f0_confidence\n",
    "    audio_features['loudness_db'] = loudness\n",
    "    \n",
    "    return audio_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breathing-adult",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_datasets = []\n",
    "\n",
    "for i in audio_dir:\n",
    "    audio_path = \n",
    "    features_datasets[i] = audio_features(audio_path)\n",
    "    \n",
    "print(np.shape(feature_datasets))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "critical-helena",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equipped-colleague",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_dir_z,'\\n',dataset_stats_file_z,'\\n',gin_file_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divided-fleece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset statistics.\n",
    "print(f'Loading dataset statistics from {dataset_stats_file_z}')\n",
    "try:\n",
    "  if tf.io.gfile.exists(dataset_stats_file_z):\n",
    "    with tf.io.gfile.GFile(dataset_stats_file_z, 'rb') as f:\n",
    "      DATASET_STATS_Z = pickle.load(f)\n",
    "except Exception as err:\n",
    "  print('Loading dataset statistics from pickle failed: {}.'.format(err),'\\n')\n",
    "\n",
    "\n",
    "# Parse gin config,\n",
    "with gin.unlock_config():\n",
    "  gin.parse_config_file(gin_file_z, skip_unknown=True)\n",
    "\n",
    "# Assumes only one checkpoint in the folder, 'ckpt-[iter]`.\n",
    "ckpt_files = [f for f in tf.io.gfile.listdir(model_dir_z) if 'ckpt' in f]\n",
    "ckpt_name = ckpt_files[0].split('.')[0]\n",
    "ckpt = os.path.join(model_dir_z, ckpt_name)\n",
    "\n",
    "# Ensure dimensions and sampling rates are equal\n",
    "time_steps_train = gin.query_parameter('F0LoudnessPreprocessor.time_steps')\n",
    "n_samples_train = gin.query_parameter('Harmonic.n_samples')\n",
    "hop_size = int(n_samples_train / time_steps_train)\n",
    "\n",
    "time_steps = int(audio.shape[1] / hop_size)\n",
    "n_samples = time_steps * hop_size\n",
    "\n",
    "# print(\"===Trained model===\")\n",
    "# print(\"Time Steps\", time_steps_train)\n",
    "# print(\"Samples\", n_samples_train)\n",
    "# print(\"Hop Size\", hop_size)\n",
    "# print(\"\\n===Resynthesis===\")\n",
    "# print(\"Time Steps\", time_steps)\n",
    "# print(\"Samples\", n_samples)\n",
    "# print('')\n",
    "\n",
    "gin_params = [\n",
    "    'Harmonic.n_samples = {}'.format(n_samples),\n",
    "    'FilteredNoise.n_samples = {}'.format(n_samples),\n",
    "    'F0LoudnessPreprocessor.time_steps = {}'.format(time_steps),\n",
    "    'oscillator_bank.use_angular_cumsum = True',  # Avoids cumsum accumulation errors.\n",
    "]\n",
    "\n",
    "with gin.unlock_config():\n",
    "  gin.parse_config(gin_params)\n",
    "\n",
    "# Set up the model just to predict audio given new conditioning\n",
    "model = ddsp.training.models.Autoencoder()\n",
    "model.restore(ckpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floral-selection",
   "metadata": {},
   "source": [
    "## Generate z datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expanded-technician",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trim all input vectors to correct lengths \n",
    "for audio_features in feature_datasets:\n",
    "    for key in ['f0_hz', 'f0_confidence', 'loudness_db']:\n",
    "      audio_features[key] = audio_features[key][:time_steps]\n",
    "    audio_features['audio'] = audio_features['audio'][:n_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hindu-creek",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_datasets = []\n",
    "for i in len(feature_datasets)\n",
    "    outputs = model_z(temp, training=False) # Run the forward pass, add losses, and create a dictionary of outputs.\n",
    "    z_feature = outputs['z']\n",
    "    z_datasets[i] = z_feature\n",
    "\n",
    "print(np.shape(z_datasets))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
